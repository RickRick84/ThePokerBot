import { useState, useEffect, useRef } from 'react';
import { useParams, Link } from 'react-router-dom';
import { FaHome } from 'react-icons/fa'; // Importamos el Ã­cono de casita
import './App.css';

// Objeto simple para gestionar las traducciones
const translations = {
Â  es: {
Â  Â  system: 'Responde solo sobre pÃ³ker en espaÃ±ol. Si te preguntan otra cosa, decÃ­ que solo hablÃ¡s de pÃ³ker.',
Â  Â  welcome: 'Â¡Hola! Soy tu asistente experto en pÃ³ker. Â¿En quÃ© puedo ayudarte hoy?',
Â  Â  placeholder: 'EscribÃ­ tu pregunta sobre pÃ³ker...',
Â  Â  sendButton: 'Enviar',
Â  Â  writing: 'Escribiendo...',
Â  Â  openaiError: (code, message) => `Error de OpenAI: ${code || 'CÃ³digo desconocido'} - ${message || 'Error desconocido'}`,
Â  Â  fetchError: 'OcurriÃ³ un error al conectarse con la API.',
Â  Â  invalidOpenAIResponse: 'No se pudo obtener una respuesta vÃ¡lida de OpenAI.',
Â  },
Â  pt: {
Â  Â  system: 'Responda apenas sobre pÃ³quer em portuguÃªs. Se perguntarem outra coisa, diga que sÃ³ fala sobre pÃ³quer.',
Â  Â  welcome: 'OlÃ¡! Eu sou o seu assistente especialista em pÃ³quer. Em que posso ajudar hoje?',
Â  Â  placeholder: 'Escreva sua pergunta sobre pÃ³quer...',
Â  Â  sendButton: 'Enviar',
Â  Â  writing: 'Escrevendo...',
Â  Â  openaiError: (code, message) => `Erro da OpenAI: ${code || 'CÃ³digo desconhecido'} - ${message || 'Erro desconhecido'}`,
Â  Â  fetchError: 'OcurriÃ³ un error al conectar con la API.',
Â  Â  invalidOpenAIResponse: 'NÃ£o foi possÃ­vel obter una resposta vÃ¡lida da OpenAI.',
Â  },
Â  en: {
Â  Â  system: 'Respond only about poker in English. If asked anything else, say you only talk about poker.',
Â  Â  welcome: 'Hello! I am your expert poker assistant. How can I help you today?',
Â  Â  placeholder: 'Type your poker question...',
Â  Â  sendButton: 'Send',
Â  Â  writing: 'Typing...',
Â  Â  openaiError: (code, message) => `OpenAI Error: ${code || 'Unknown Code'} - ${message || 'Unknown Error'}`,
Â  Â  fetchError: 'An error occurred while connecting to the API.',
Â  Â  invalidOpenAIResponse: 'Could not get a valid response from OpenAI.',
Â  },
};


function ChatPage() { // Nombre del componente
Â  const { lang } = useParams();
Â  const [currentLang, setCurrentLang] = useState(lang || 'es');

Â  // Obtenemos las traducciones para el idioma actual, o espaÃ±ol si no se encuentra
Â  const t = translations[currentLang] || translations['es'];


Â  const [messages, setMessages] = useState([
Â  Â  { role: 'system', content: t.system },
Â  Â  { role: 'assistant', content: t.welcome }
Â  ]);
Â  const [input, setInput] = useState('');
Â  const [loading, setLoading] = useState(false);

Â  const chatBoxRef = useRef(null);
Â  const lastMessageRef = useRef(null); // <-- Referencia al Ãºltimo mensaje para scrollear a Ã©l


Â  // Creamos una referencia a un objeto de Audio para el sonido del botÃ³n Enviar
Â  const sendAudioRef = useRef(new Audio('/sounds/button-click.mp3')); // <-- AsegÃºrate que esta ruta y nombre de archivo sean correctos

Â  // FunciÃ³n para reproducir el sonido de envÃ­o
Â  const playSendSound = () => {
Â  Â  // Reinicia el sonido al principio
Â  Â  sendAudioRef.current.currentTime = 0;
Â  Â  // Intenta reproducir el sonido
Â  Â  sendAudioRef.current.play().catch(error => console.error("Error playing send sound:", error));
Â  };


Â  // Efecto para scrollear al inicio del Ãºltimo mensaje cuando los mensajes cambian
Â  useEffect(() => {
Â  Â  // Solo scrollear si tenemos una referencia al Ãºltimo mensaje Y hay mensajes mÃ¡s allÃ¡ del inicial del sistema.
Â  Â  // TambiÃ©n disparamos el scroll cuando loading cambia, para reaccionar al fin de la carga.
Â  Â  Â if (lastMessageRef.current && messages.length > 1) {
Â  Â  Â  Â  Â  // Usamos un pequeÃ±o timeout para asegurarnos de que el DOM se actualizÃ³ con el Ãºltimo mensaje
Â  Â  Â  Â  Â  // El timeout es crucial porque los mensajes se agregan al estado, pero la renderizaciÃ³n
Â  Â  Â  Â  Â  // del DOM puede tomar un instante, especialmente con respuestas largas.
Â  Â  Â  Â  Â  const timeoutId = setTimeout(() => {
Â  Â  Â  Â  Â  Â  Â  Â console.log("Attempting to scroll to:", lastMessageRef.current);
Â  Â  Â  Â  Â  Â  Â  Â lastMessageRef.current.scrollIntoView({ behavior: 'smooth', block: 'start' });
Â  Â  Â  Â  Â  }, 100); // Aumentamos el delay a 100ms. Si sigue fallando, prueba con 200ms.
Â  Â  Â  Â  Â  return () => clearTimeout(timeoutId); // Limpiar el timeout si los mensajes cambian de nuevo rÃ¡pido
Â  Â  Â } else if (chatBoxRef.current && messages.length <= 1) {
Â  Â  Â  Â  Â  // Comportamiento al inicio del chat o solo con el mensaje del sistema: scrollear al fondo
Â  Â  Â  Â  Â  chatBoxRef.current.scrollTop = chatBoxRef.current.scrollHeight;
Â  Â  Â }
Â  }, [messages, loading]); // Depende de los mensajes y el estado de carga


Â  // Efecto para actualizar el idioma si cambia el parÃ¡metro de la URL
Â  useEffect(() => {
Â  Â  Â  setCurrentLang(lang || 'es');
Â  Â  Â  // Si quieres reiniciar la conversaciÃ³n al cambiar de idioma en la URL, descomenta lo siguiente:
Â  Â  Â  // setMessages([ { role: 'system', content: translations[lang]?.system || translations['es'].system }, { role: 'assistant', content: translations[lang]?.welcome || translations['es'].welcome } ]);
Â  }, [lang]);


Â  // LÃ³gica principal para enviar el mensaje (AHORA MANEJA STREAMING Y NO-STREAMING)
Â  const sendMessageLogic = async () => {
Â  Â  if (!input.trim()) return;

Â  Â  const userMessage = { role: 'user', content: input };
Â  Â  // Agregamos el mensaje del usuario y un placeholder para la respuesta del asistente
Â  Â  setMessages(currentMessages => [...currentMessages, userMessage, { role: 'assistant', content: '' }]); // AÃ±adimos un mensaje vacÃ­o para el streaming
Â  Â  setInput('');
Â  Â  setLoading(true);

Â  Â  try {
Â  Â  Â  const url = '/api/chat';
Â  Â  Â  console.log("Usando backend:", url);

Â  Â  Â  const payload = {
Â  Â  Â  Â  model: 'gpt-4-turbo',
Â  Â  Â  Â  messages: [...messages, userMessage], // Enviar todos los mensajes incluyendo el Ãºltimo del usuario
Â  Â  Â  Â  temperature: 0.7,
Â  Â  Â  };

Â  Â  Â  console.log("ğŸ“¤ Enviando a backend:", payload);

Â  Â  Â  const response = await fetch(url, {
Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  headers: {
Â  Â  Â  Â  Â  'Content-Type': 'application/json',
Â  Â  Â  Â  },
Â  Â  Â  Â  body: JSON.stringify(payload),
Â  Â  Â  });

Â  Â  Â  // Verificar si la respuesta es un error HTTP
Â  Â  Â  if (!response.ok) {
Â  Â  Â  Â  Â  // Si la respuesta no es OK, intentamos leerla como JSON (puede ser un error de la API)
Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  const errorData = await response.json();
Â  Â  Â  Â  Â  Â  console.error('âŒ Error en la respuesta del backend:', response.status, errorData);
Â  Â  Â  Â  Â  Â  // Mostrar un mensaje de error en el chat (modificando el Ãºltimo mensaje vacÃ­o)
Â  Â  Â  Â  Â  Â  setMessages(currentMessages => {
Â  Â  Â  Â  Â  Â  Â  const lastMessageIndex = currentMessages.length - 1;
Â  Â  Â  Â  Â  Â  Â  const updatedMessages = [...currentMessages];
Â  Â  Â  Â  Â  Â  Â  updatedMessages[lastMessageIndex] = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  role: 'assistant',
Â  Â  Â  Â  Â  Â  Â  Â  Â  content: errorData.error || `HTTP error! status: ${response.status}`
Â  Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  Â  return updatedMessages;
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  } catch (jsonError) {
Â  Â  Â  Â  Â  Â  // Si no pudimos leer el error como JSON, mostramos un error HTTP genÃ©rico
Â  Â  Â  Â  Â  Â  console.error('âŒ Error HTTP no-JSON en la respuesta del backend:', response.status, jsonError);
Â  Â  Â  Â  Â  Â  setMessages(currentMessages => {
Â  Â  Â  Â  Â  Â  Â  const lastMessageIndex = currentMessages.length - 1;
Â  Â  Â  Â  Â  Â  Â  const updatedMessages = [...currentMessages];
Â  Â  Â  Â  Â  Â  Â  updatedMessages[lastMessageIndex] = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  role: 'assistant',
Â  Â  Â  Â  Â  Â  Â  Â  Â  content: `HTTP error! status: ${response.status}`
Â  Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  Â  return updatedMessages;
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  return; // Salir de la funciÃ³n si hay un error
Â  Â  Â  }

        // --- PROCESAR LA RESPUESTA (AHORA SOPORTA STREAMING Y NO-STREAMING) ---
        const contentType = response.headers.get('Content-Type');

        if (contentType && contentType.includes('text/event-stream')) {
            // --- MANEJAR RESPUESTA STREAMING (SSE) ---
            console.log("âœ… Recibiendo respuesta streaming (SSE).");
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = ''; // Acumula los chunks
            let assistantResponse = ''; // Acumula el contenido del asistente
            let messageIndexToUpdate = messages.length; // Ãndice del mensaje del asistente que estamos construyendo (el que aÃ±adimos vacÃ­o)

            // No eliminamos el mensaje vacÃ­o temporal, lo usaremos para construir la respuesta.
            // setMessages(currentMessages => currentMessages.slice(0, -1)); // Eliminada esta lÃ­nea


            while (true) {
                const { value, done } = await reader.read();
                if (done) {
                    console.log("Stream terminado.");
                    break; // El stream terminÃ³
                }

                // Decodifica el chunk y lo aÃ±ade al buffer
                buffer += decoder.decode(value, { stream: true });

                // Procesa el buffer lÃ­nea por lÃ­nea, buscando delimitadores SSE (\n\n)
                const lines = buffer.split('\n\n');
                buffer = lines.pop(); // Mantiene el Ãºltimo fragmento incompleto

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const jsonStr = line.substring(6); // Elimina el prefijo "data: "
                        if (jsonStr === '[DONE]') {
                            console.log("Recibido [DONE], stream completo.");
                            continue; // Ignorar el mensaje de fin de stream
                        }
                        if (jsonStr) {
                            try {
                                const chunk = JSON.parse(jsonStr);
                                // Procesa el chunk para extraer el contenido de la respuesta
                                const deltaContent = chunk.choices?.[0]?.delta?.content;
                                if (deltaContent) {
                                    assistantResponse += deltaContent;
                                    // Actualiza el Ãºltimo mensaje en el estado con el contenido acumulado
                                    setMessages(currentMessages => {
                                        const updatedMessages = [...currentMessages];
                                        // Actualiza el mensaje del asistente en el Ã­ndice correcto
                                        updatedMessages[messageIndexToUpdate] = {
                                            role: 'assistant', // Aseguramos el rol
                                            content: assistantResponse
                                        };
                                        return updatedMessages;
                                    });
                                }
                            } catch (e) {
                                console.error("âŒ Error parsing stream chunk JSON:", jsonStr, e);
                                // Si hay un error de parseo en un chunk, mostramos un error en un nuevo mensaje
                                setMessages(currentMessages => [...currentMessages, {
                                     role: 'assistant',
                                     content: t.fetchError + ' (Error de parseo en stream: ' + e.message + ')'
                                }]);
                                reader.cancel(); // Cancelar la lectura del stream si hay error
                                break; // Salir del loop while(true)
                            }
                        }
                    } else if (line) {
                         // Manejar lÃ­neas que no tienen el prefijo "data: ",
                         // si tu backend no lo aÃ±ade pero sÃ­ envÃ­a JSONs separados por \n\n
                         // Este bloque es menos comÃºn para streams SSE directos de OpenAI pero lo mantenemos por robustez.
                         try {
                            const chunk = JSON.parse(line);
                            const deltaContent = chunk.choices?.[0]?.delta?.content;
                            if (deltaContent) {
                                assistantResponse += deltaContent;
                                setMessages(currentMessages => {
                                    const updatedMessages = [...currentMessages];
                                    updatedMessages[messageIndexToUpdate] = {
                                         role: 'assistant', // Aseguramos el rol
                                         content: assistantResponse
                                    };
                                    return updatedMessages;
                                });
                            }
                         } catch (e) {
                            console.error("âŒ Error parsing raw JSON line:", line, e);
                             setMessages(currentMessages => [...currentMessages, {
                                 role: 'assistant',
                                 content: t.fetchError + ' (Error de parseo de lÃ­nea raw: ' + e.message + ')'
                            }]);
                            reader.cancel();
                            break;
                         }
                    }
                }
            }
            // DespuÃ©s de que el while(true) termine (done es true o se cancelÃ³)
            console.log("Fin del procesamiento del stream.");
            // No hacemos nada aquÃ­ con setMessages porque ya se actualizÃ³ en el loop.


        } else {
            // --- MANEJAR RESPUESTA NO-STREAMING (JSON completo) ---
            console.log("ğŸ“¦ Recibiendo respuesta JSON completa (no streaming).");
            const data = await response.json(); // Esperamos el JSON completo

            if (data.choices && data.choices.length > 0 && data.choices[0].message) {
                 // Reemplaza el Ãºltimo mensaje vacÃ­o temporal con la respuesta completa
                setMessages(currentMessages => {
                     const lastMessageIndex = currentMessages.length - 1; // El Ãºltimo que aÃ±adimos (placeholder)
                     const updatedMessages = [...currentMessages];
                     updatedMessages[lastMessageIndex] = data.choices[0].message; // Reemplaza el placeholder
                     return updatedMessages;
                });
            } else if (data.error) {
                console.error("âŒ Error en la respuesta de OpenAI (no stream):", data.error);
                 // Modifica el Ãºltimo mensaje vacÃ­o con el error
                 setMessages(currentMessages => {
                    const lastMessageIndex = currentMessages.length - 1;
                    const updatedMessages = [...currentMessages];
                    updatedMessages[lastMessageIndex] = {
                         role: 'assistant',
                         content: t.openaiError(data.error.code, data.error.message)
                    };
                    return updatedMessages;
                 });
            } else {
                console.error("âŒ Formato inesperado de respuesta de OpenAI (no stream):", data);
                 // Modifica el Ãºltimo mensaje vacÃ­o con el error
                 setMessages(currentMessages => {
                    const lastMessageIndex = currentMessages.length - 1;
                    const updatedMessages = [...currentMessages];
                    updatedMessages[lastMessageIndex] = {
                         role: 'assistant',
                         content: t.invalidOpenAIResponse
                    };
                    return updatedMessages;
                 });
            }
        }


Â  Â  } catch (error) {
Â  Â  Â  console.error("âŒ Error general en fetch:", error); // <-- console.error mantenido
Â  Â  Â  // Mostrar un mensaje de error general de conexiÃ³n o fetch (modificando el Ãºltimo mensaje vacÃ­o)
Â  Â  Â  Â setMessages(currentMessages => {
             const lastMessageIndex = currentMessages.length - 1;
             const updatedMessages = [...currentMessages];
             updatedMessages[lastMessageIndex] = {
                  role: 'assistant',
                  content: t.fetchError + ' (' + error.message + ')' // Incluir mensaje del error
             };
             return updatedMessages;
         });

Â  Â  } finally {
Â  Â  Â  setLoading(false); // Terminar carga
Â  Â  }
Â  };

Â  // Handler para el click del botÃ³n (llama a la lÃ³gica de envÃ­o)
Â  const handleButtonClick = () => {
Â  Â  Â  playSendSound(); // Reproduce el sonido
Â  Â  Â  sendMessageLogic(); // Llama a la lÃ³gica de envÃ­o
Â  }

Â  // Handler para la tecla Enter en el input (llama a la lÃ³gica de envÃ­o)
Â  const handleKeyDownOptimized = (e) => {
Â  Â  Â  if (e.key === 'Enter') {
Â  Â  Â  Â  e.preventDefault(); // Previene la acciÃ³n por defecto del Enter
Â  Â  Â  Â  if (!loading) { // Solo enviar si no estamos cargando ya
Â  Â  Â  Â  Â  Â playSendSound(); // Reproduce el sonido
Â  Â  Â  Â  Â  Â sendMessageLogic(); // Llama a la lÃ³gica de envÃ­o
Â  Â  Â  Â  }
Â  Â  Â  }
Â  }


Â  return (
Â  Â  // Usamos Fragment <> </> para poder retornar el Link Y el div.app
Â  Â  <>
Â  Â  Â  {/* Enlace con Ã­cono de Home */}
Â  Â  Â  {/* AsegÃºrate que el tamaÃ±o y posiciÃ³n aquÃ­ sea el que te gustÃ³ */}
Â  Â  Â  <Link to="/" className="home-link">
Â  Â  Â  Â  <FaHome size={15} /> {/* Verifica este tamaÃ±o */}
Â  Â  Â  </Link>

Â  Â  Â  {/* Contenedor principal con estilo fijo y centrado */}
Â  Â  Â  <div className="app chat-page-container">

Â  Â  Â  Â  {/* Estructura y estilos para el logo */}
Â  Â  Â  Â  <div className="title-container">
Â  Â  Â  Â  Â  <img src="/i_love_poker_logo_.png" alt="The Poker Bot Logo" className="title-image" />
Â  Â  Â  Â  </div>

Â  Â  Â  Â  {/* La caja de chat con el scroll */}
Â  Â  Â  Â  <div className="chat-box" ref={chatBoxRef}>
Â  Â  Â  Â  Â  {messages.slice(1).map((msg, idx, arr) => ( // slice(1) para no mostrar mensaje system
Â  Â  Â  Â  Â  Â  // AÃ±adimos la referencia al Ãºltimo elemento
Â  Â  Â  Â  Â  Â  <div
Â  Â  Â  Â  Â  Â  Â  key={idx}
Â  Â  Â  Â  Â  Â  Â  className={`message ${msg.role}`}
Â  Â  Â  Â  Â  Â  Â  ref={idx === arr.length - 1 ? lastMessageRef : null} // <-- Asigna la ref al Ãºltimo mensaje
Â  Â  Â  Â  Â  Â  >
Â  Â  Â  Â  Â  Â  Â  <span>{msg.content}</span>
Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  ))}
Â  Â  Â  Â  Â  Â {/* Mensaje de "Escribiendo..." (visible mientras loading sea true) */}
Â  Â  Â  Â  Â  Â {loading && (
Â  Â  Â  Â  Â  Â  Â  Â <div className="message assistant">
Â  Â  Â  Â  Â  Â  Â  Â  Â <span>{t.writing}</span>
Â  Â  Â  Â  Â  Â  Â  Â </div>
Â  Â  Â  Â  Â  Â )}
Â  Â  Â  Â  </div>

Â  Â  Â  Â  {/* La barra de entrada */}
Â  Â  Â  Â  <div className="input-bar">
Â  Â  Â  Â  Â  <input
Â  Â  Â  Â  Â  Â  value={input}
Â  Â  Â  Â  Â  Â  onChange={(e) => setInput(e.target.value)}
Â  Â  Â  Â  Â  Â  onKeyDown={handleKeyDownOptimized}
Â  Â  Â  Â  Â  Â  placeholder={t.placeholder}
Â  Â  Â  Â  Â  Â  disabled={loading} // Deshabilitar input mientras carga
Â  Â  Â  Â  Â  />
Â  Â  Â  Â  Â  <button onClick={handleButtonClick} disabled={loading}>{t.sendButton}</button>
Â  Â  Â  Â  </div>
Â  Â  Â  </div>
Â  Â  </> // Cerramos el Fragment
Â  );
}

export default ChatPage; // Exportamos el componente